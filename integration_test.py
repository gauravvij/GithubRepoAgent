"""
integration_test.py - Integration test for the codebase analysis agent.

Feeds the test_project directory to the agent, triggers the initial
analysis report, then simulates a follow-up query about entry points.
All output is written to stdout and saved to analysis_report.md.
"""

import os
import sys
import logging
from datetime import datetime

PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, PROJECT_ROOT)

from agent import CodebaseAnalysisAgent

logging.basicConfig(
    level=logging.INFO,
    handlers=[logging.StreamHandler(sys.stdout)],
    format="%(levelname)s: %(message)s",
)
logger = logging.getLogger(__name__)

FOLLOW_UP_QUESTION = "What are the main entry points and how do they interact?"
REPORT_OUTPUT_PATH = os.path.join(PROJECT_ROOT, "analysis_report.md")


def run_test():
    """
    Execute the integration test:
    1. Point the agent at the test_project directory.
    2. Generate the initial codebase analysis report.
    3. Ask a follow-up question about entry points.
    4. Print all output to stdout and save to analysis_report.md.
    5. Verify output quality with assertion checks.
    """
    test_project_dir = os.path.join(PROJECT_ROOT, "test_project")

    if not os.path.isdir(test_project_dir):
        print(f"ERROR: test_project directory not found at: {test_project_dir}")
        sys.exit(1)

    print("=" * 70)
    print("  CODEBASE ANALYSIS AGENT - INTEGRATION TEST")
    print("=" * 70)
    print(f"Target project: {test_project_dir}")
    print(f"Test date: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}\n")

    # Initialize agent
    agent = CodebaseAnalysisAgent()

    # ------------------------------------------------------------------ #
    # Step 1: Generate initial analysis report
    # ------------------------------------------------------------------ #
    print(">>> STEP 1: Generating initial codebase analysis report...\n")
    report = agent.analyze_project(test_project_dir)

    print("=" * 70)
    print("  INITIAL CODEBASE ANALYSIS REPORT")
    print("=" * 70)
    print(report)
    print()

    # ------------------------------------------------------------------ #
    # Step 2: Simulate follow-up query
    # ------------------------------------------------------------------ #
    print("=" * 70)
    print(f"  FOLLOW-UP QUERY: {FOLLOW_UP_QUESTION}")
    print("=" * 70)
    print(">>> STEP 2: Asking follow-up question...\n")

    answer = agent.ask(FOLLOW_UP_QUESTION)

    print("AGENT ANSWER:")
    print("-" * 50)
    print(answer)
    print("-" * 50)
    print()

    # ------------------------------------------------------------------ #
    # Step 3: Save combined report to file
    # ------------------------------------------------------------------ #
    report_date = datetime.utcnow().strftime("%Y-%m-%d %H:%M UTC")
    report_content = f"""# Codebase Analysis Agent - Integration Test Report

**Project Analyzed:** `{test_project_dir}`  
**Model Used:** `{agent.model}`  
**Test Date:** {report_date}

---

## Initial Codebase Analysis Report

{report}

---

## Follow-Up Query

**Question:** {FOLLOW_UP_QUESTION}

**Answer:**

{answer}

---

*Report generated by integration_test.py*
"""

    with open(REPORT_OUTPUT_PATH, "w", encoding="utf-8") as f:
        f.write(report_content)

    print(f">>> Report saved to: {REPORT_OUTPUT_PATH}")
    print("\n>>> INTEGRATION TEST COMPLETE")
    print("=" * 70)

    # ------------------------------------------------------------------ #
    # Step 4: Verify outputs contain expected sections
    # ------------------------------------------------------------------ #
    print("\n>>> STEP 4: Verifying output quality...\n")

    checks = {
        "Report contains 'Project Overview'": "project overview" in report.lower(),
        "Report contains file descriptions": "file" in report.lower(),
        "Report contains dependencies/imports": (
            "dependenc" in report.lower() or "import" in report.lower()
        ),
        "Report contains entry points": "entry" in report.lower(),
        "Follow-up answer references app.py or entry": (
            "app.py" in answer.lower() or "entry" in answer.lower()
        ),
        "Follow-up answer is substantive (>50 chars)": len(answer.strip()) > 50,
        "Conversation history preserved (>=4 messages)": (
            len(agent.conversation_history) >= 4
        ),
        "Report saved to disk": os.path.isfile(REPORT_OUTPUT_PATH),
    }

    all_passed = True
    for check, passed in checks.items():
        status = "PASS" if passed else "FAIL"
        if not passed:
            all_passed = False
        print(f"  [{status}] {check}")

    print()
    if all_passed:
        print(">>> ALL CHECKS PASSED")
    else:
        print(">>> SOME CHECKS FAILED - review output above")

    return all_passed


if __name__ == "__main__":
    success = run_test()
    sys.exit(0 if success else 1)
